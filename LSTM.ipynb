{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.4 64-bit"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "interpreter": {
      "hash": "0c351a98dd9a813c5b13d413147a133d8a9165b013c14b51647aff9ea604b678"
    },
    "colab": {
      "name": "problem_0801.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tiziri-k/SIC-exercices/blob/master/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gF8tvrIfyLD"
      },
      "source": [
        "## Quiz #0801"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr9NvUX_fyLS"
      },
      "source": [
        "### \"Text Classification with Keras\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj7hyUxkfyLW",
        "outputId": "e784a3b7-691b-423c-cb39-132f1001cc70"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import os\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.datasets import load_files\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, SimpleRNN, LSTM, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.preprocessing import sequence\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Slash\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 402
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfcw5KyOfyLe"
      },
      "source": [
        "#### Answer the following question by providing Python code:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynuDYMWmfyLg"
      },
      "source": [
        "1). Read in the movie review data from Cornell CS department. Carry out the EDA. <br>\n",
        "- The data can be found [here](https://www.cs.cornell.edu/people/pabo/movie-review-data). <br>\n",
        "- Download the “polarity dataset” and unzip. <br>\n",
        "- Under the \"txt_sentoken” folder, there are “pos” and “neg\" subfolders. <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8cSRucBfyLh"
      },
      "source": [
        "reviews = load_files('txt_sentoken/')\n",
        "x, y = reviews.data, reviews.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oVDyDv6fyLk",
        "outputId": "a0b7570a-a451-4878-ae01-3e6db483d556"
      },
      "source": [
        "print(\"Number of features :\", len(x),\"\\nNumber of target :\" ,len(y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features : 2000 \n",
            "Number of target : 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O178HRpvfyLn"
      },
      "source": [
        "2). Carry out the data preprocessing: <br>\n",
        "- Cleaning.\n",
        "- Stopword removal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPBoJtWnfyLv"
      },
      "source": [
        "def clean_text(txt):\n",
        "    stpw = stopwords.words('english')\n",
        "    stpw.extend(['www','http','utc'])\n",
        "    stpw = set(stpw)\n",
        "    \n",
        "    txt = re.sub(r\"\\n\", \" \", txt)\n",
        "    txt = re.sub(\"[\\<\\[].*?[\\>\\]]\", \" \", txt)\n",
        "    txt = txt.lower()\n",
        "    txt = re.sub(r\"[^a-z ]\", \" \", txt)\n",
        "    txt = re.sub(r\"\\b\\w{1,3}\\b\", \" \",txt)\n",
        "    txt = \" \".join([x for x in txt.split() if x not in stpw])\n",
        "    \n",
        "    return txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21LlSkgLfyLz"
      },
      "source": [
        "my_doc =[]\n",
        "for i in range(len(x)):\n",
        "    my_doc.append(nltk.sent_tokenize(str(x[i])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqf0JObJfyL0",
        "outputId": "983eb6cd-4011-482d-a7df-6eeee1074eb6"
      },
      "source": [
        "my_doc[0][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'b\"arnold schwarzenegger has been an icon for action enthusiasts , since the late 80\\'s , but lately his films have been very sloppy and the one-liners are getting worse .'"
            ]
          },
          "metadata": {},
          "execution_count": 407
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKU9143hfyL1"
      },
      "source": [
        "\n",
        "for i in range(len(my_doc)):\n",
        "    for j in range(len(my_doc[i])):\n",
        "      my_doc[i][j] = clean_text(my_doc[i][j])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R2JCVxefyL3",
        "outputId": "1ccc5d5b-5f0a-405b-d5aa-92e65df74839"
      },
      "source": [
        "len(my_doc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 409
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqPrv2tZfyL5",
        "outputId": "1158ef9d-bfbc-49f0-bdf4-d9304b519f84"
      },
      "source": [
        "\n",
        "X=[]\n",
        "for i in range(len(my_doc)):\n",
        "    x=  ' '.join(my_doc[i])\n",
        "    X.append(x)\n",
        "X[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'arnold schwarzenegger icon action enthusiasts since late lately films sloppy liners getting worse hard seeing arnold freeze batman robin especially says tons jokes million matter nonce arnold signed another expensive blockbuster compare likes terminator series true lies even eraser called dark thriller devil gabriel byrne come upon earth impregnate woman robin tunney happens every years basically destroy world apparently chosen jericho cane arnold nwith help trusty sidekick kevin pollack stop nothing devil take world nparts actually absurd would right dogma nyes film weak better blockbuster right sleepy hollow makes world enough look like star film nanyway definitely seem like arnold movie type film nsure gave chuckles well known liners seemed confused character film going understandable especially ending changed according sources naside form still walked much like past films sorry arnold maybe action days nspeaking action film nthere hardly explosions fights nthe devil made places explode arnold kicking devil butt nthe ending changed make spiritual undoubtedly ruined film least hoping cool ending nothing else occurred also know film took long cost much nthere really super affects unless consider invisible devil minutes tops worth overpriced budget nthe budget gone better script least audiences could somewhat entertained instead facing boredom pitiful scripts like bought made movie even read things anymore sure seem like nthankfully gabriel performance gave light poor film nwhen walks street searching robin tunney help feel looked like devil nthe creepy looking anyway nwhen glad movie ndon bother expecting solid action flick neither solid action another movie suckered seeing strategic marketing campaign nsave money world enough entertaining experience '"
            ]
          },
          "metadata": {},
          "execution_count": 410
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUPknivZfyL-"
      },
      "source": [
        "3). Carry out label encoding by integers (required form by Keras):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qu_5Ql7pfyMA"
      },
      "source": [
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.text import text_to_word_sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKgzw9NYfyMB"
      },
      "source": [
        "\n",
        "encoding =[]\n",
        "for i in range(len(X)):\n",
        "      words = set(text_to_word_sequence(X[i]))\n",
        "      vocab_size = len(words)\n",
        "      encoding.append(one_hot(X[i], round(vocab_size*1.3)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ourYfT3EfyMC"
      },
      "source": [
        "4). Prepare the data for AI: <br>\n",
        "- Apply the padding.\n",
        "- Split the data into training and testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97B1ZS4ifyMC"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA-NxBf1fyMD"
      },
      "source": [
        "padded_inputs =pad_sequences(encoding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8oNFbMGfyME"
      },
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(padded_inputs,y,test_size=0.2,random_state=123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIoYJ1LUfyME"
      },
      "source": [
        "5). Define the AI model (Embedding + LSTM):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anM57yKmfyMF"
      },
      "source": [
        "from tensorflow.keras.layers import SpatialDropout1D\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(1600, 100, input_length=1308))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTUj79O4fyMG"
      },
      "source": [
        "6). Define the optimizer and compile the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6_DYJsFfyMG"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXVGLahTfyMG"
      },
      "source": [
        "7). Train the model and visualize the summary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCjy62CxfyMH",
        "outputId": "883770e5-0e96-4ecb-89c0-3c72c0b6cbf7"
      },
      "source": [
        "x_train.shape , y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1600, 1308), (1600,))"
            ]
          },
          "metadata": {},
          "execution_count": 418
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GFH-vl5fyMI"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pexbIs71fyMI",
        "outputId": "b0ce01b8-b4f1-4c0b-9917-519b96a96115"
      },
      "source": [
        "epochs = 8\n",
        "batch_size = 64\n",
        "# Code Here\n",
        "history = model.fit(x_train, y_train, epochs=epochs,\n",
        "           batch_size=batch_size,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "18/25 [====================>.........] - ETA: 1:42 - loss: 0.6931 - accuracy: 0.4774"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTnN9yuyfyMJ"
      },
      "source": [
        "8). Display the test result (accuracy):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTGiIGktfyMM"
      },
      "source": [
        "results =  model.evaluate(x_test , y_test)\n",
        "print('loss {:.3f}\\nAccuracy {:.3f}%'.format(results[0],results[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}