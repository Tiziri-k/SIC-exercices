{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.4 64-bit"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "interpreter": {
      "hash": "0c351a98dd9a813c5b13d413147a133d8a9165b013c14b51647aff9ea604b678"
    },
    "colab": {
      "name": "problem_0801.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tiziri-k/SIC-exercices/blob/master/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX5IcmR_XqgE"
      },
      "source": [
        "## Quiz #0801"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nu7PSxeMXqgR"
      },
      "source": [
        "### \"Text Classification with Keras\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BTF5ODiXqgS",
        "outputId": "576fce5a-0714-4cfb-8f00-2d60e1ecec49"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import os\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.datasets import load_files\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, SimpleRNN, LSTM, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.preprocessing import sequence\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Slash\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5FS0183XqgV"
      },
      "source": [
        "#### Answer the following question by providing Python code:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w98TyslTXqgW"
      },
      "source": [
        "1). Read in the movie review data from Cornell CS department. Carry out the EDA. <br>\n",
        "- The data can be found [here](https://www.cs.cornell.edu/people/pabo/movie-review-data). <br>\n",
        "- Download the “polarity dataset” and unzip. <br>\n",
        "- Under the \"txt_sentoken” folder, there are “pos” and “neg\" subfolders. <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pc0w5eIFXqgX"
      },
      "source": [
        "reviews = load_files('txt_sentoken/')\n",
        "x, y = reviews.data, reviews.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNAWDzOUXqgY",
        "outputId": "ee8637a7-c0d0-4caf-fc74-4669a41e3900"
      },
      "source": [
        "print(\"Number of features :\", len(x),\"\\nNumber of target :\" ,len(y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features : 2000 \n",
            "Number of target : 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YbZ7OdMXqgZ"
      },
      "source": [
        "2). Carry out the data preprocessing: <br>\n",
        "- Cleaning.\n",
        "- Stopword removal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul10AtOoXqga"
      },
      "source": [
        "def clean_text(txt):\n",
        "    stpw = stopwords.words('english')\n",
        "    stpw.extend(['www','http','utc'])\n",
        "    stpw = set(stpw)\n",
        "    \n",
        "    txt = re.sub(r\"\\n\", \" \", txt)\n",
        "    txt = re.sub(\"[\\<\\[].*?[\\>\\]]\", \" \", txt)\n",
        "    txt = txt.lower()\n",
        "    txt = re.sub(r\"[^a-z ]\", \" \", txt)\n",
        "    txt = re.sub(r\"\\b\\w{1,3}\\b\", \" \",txt)\n",
        "    txt = \" \".join([x for x in txt.split() if x not in stpw])\n",
        "    \n",
        "    return txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Qh_V81lXqgb"
      },
      "source": [
        "my_doc =[]\n",
        "for i in range(len(x)):\n",
        "    my_doc.append(nltk.sent_tokenize(str(x[i])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhcsMU6iXqgb",
        "outputId": "0c9911b8-b65a-40d8-fa64-2236ae64b0b3"
      },
      "source": [
        "my_doc[0][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'b\"arnold schwarzenegger has been an icon for action enthusiasts , since the late 80\\'s , but lately his films have been very sloppy and the one-liners are getting worse .'"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HQVu6msXqgb"
      },
      "source": [
        "\n",
        "for i in range(len(my_doc)):\n",
        "    for j in range(len(my_doc[i])):\n",
        "      my_doc[i][j] = clean_text(my_doc[i][j])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0Lt-20GXqgc",
        "outputId": "f158e436-8f7d-4af3-fbf7-f15ab30aee01"
      },
      "source": [
        "len(my_doc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72XmYALCXqgc",
        "outputId": "0bfe8f70-36d2-4f8c-c88f-ac7c5cf1f4d7"
      },
      "source": [
        "\n",
        "X=[]\n",
        "for i in range(len(my_doc)):\n",
        "    x=  ' '.join(my_doc[i])\n",
        "    X.append(x)\n",
        "X[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a'"
            ]
          },
          "metadata": {},
          "execution_count": 331
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXYBDwtLXqgc"
      },
      "source": [
        "3). Carry out label encoding by integers (required form by Keras):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBjTjocqXqgd"
      },
      "source": [
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.text import text_to_word_sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vz0E8bU5Xqgd"
      },
      "source": [
        "\n",
        "encoding =[]\n",
        "for i in range(len(X)):\n",
        "      words = set(text_to_word_sequence(X[i]))\n",
        "      vocab_size = len(words)\n",
        "      encoding.append(one_hot(X[i], round(vocab_size*1.3)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UwJMj5GXqgd"
      },
      "source": [
        "4). Prepare the data for AI: <br>\n",
        "- Apply the padding.\n",
        "- Split the data into training and testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vhlyw_oDXqge"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pS7YVPhPXqge"
      },
      "source": [
        "padded_inputs =pad_sequences(encoding, padding=\"post\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q4GVr1xXqgf"
      },
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(padded_inputs,y,test_size=0.2,random_state=123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6qkyOH9Xqgf"
      },
      "source": [
        "5). Define the AI model (Embedding + LSTM):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXwOn2YXXqgg"
      },
      "source": [
        "from tensorflow.keras.layers import SpatialDropout1D\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(1000, 64, input_length=100))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(100, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QxA6W1RXqgg"
      },
      "source": [
        "6). Define the optimizer and compile the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxZ1Kwy3Xqgg"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQw8OPAlXqgg"
      },
      "source": [
        "7). Train the model and visualize the summary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFRDWP0qXqgh",
        "outputId": "556c6264-d9cf-4d8c-d4d6-e49222accc6a"
      },
      "source": [
        "x_train.shape , y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1600, 1308), (1600,))"
            ]
          },
          "metadata": {},
          "execution_count": 352
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIRzhDfLXqgh"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-rssn23Xqgh"
      },
      "source": [
        "epochs = 5\n",
        "batch_size = 64\n",
        "# Code Here\n",
        "history = model.fit(x_train, y_train, epochs=epochs,\n",
        "           batch_size=batch_size,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-4fm7k0Xqgi"
      },
      "source": [
        "8). Display the test result (accuracy):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEVxhTMSXqgi"
      },
      "source": [
        "results =  model.evaluate(x_test , y_test)\n",
        "print('loss {:.3f}\\nAccuracy {:.3f}%'.format(results[0],results[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}